% Chapter 3

\chapter{OSR in RJIT} % Main chapter title

\label{Chapter4} % For referencing the chapter elsewhere, use \ref{Chapter2} 

%----------------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content 
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\tabhead}[1]{\textbf{#1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\file}[1]{\texttt{\bfseries#1}}
\newcommand{\option}[1]{\texttt{\itshape#1}}

%----------------------------------------------------------------------------------------
\section{Overview}
\subsection{Justification}

REWRITE - REFORMULATE.\\
%Goal of the thesis 
    %on stack replacement general mechanism, reusable, at llvm level
    %Why? improve performance and allow greater flexibility in RJIT
        %R is slow, 
        %R is a dynamic language lots of difficulties for implement opt
        %Hence OSR. 
%Reuse an existing library to focus on deoptimization
    %Our goal is to aggressively optimize while preserving correctness
    %Project still young, don't know exactly what we need, don't have feedback on the code
    %Hence better to reuse lib that we can modifiy -> OSR Kit 
%Restate goals 
    %Try to specialise the OSR Kit for the deopt and overcome the limitations. 
    %Will test it with an inlining. 
            

The goal of this Master Thesis project is to provide a flexible OSR deoptimization framework in LLVM, and use it to improve performances in RJIT, our LLVM JIT compiler for R.
R is a programming language and software environment for the statistical computing and graphics, developed by the R Foundation for Statistical Computing\cite{RURL}.
Due to SAY WHYYYYYYYYYYYYYYYYYYYYYYYYYY OOOOOHHHHH GOOOOOOODDDDDD WHHHYYYYYYYYYY, R exhibits very poor performances CITE SOMETHING.
The RJIT project strives to improve these performances by providing a LLVM based JIT compiler for R. SAY MORE.
The RJIT compiler is still pretty young, only a few months old.
As a result, we lack FEEDBACK; DONT KNOW EXACTLY HOW TO IMPROVE PERF AND NEED TO EXPERIMENT.
Therefore, we are looking for a flexible and extensible OSR mechanism that enables us to prototype and experiment various solutions, without trapping ourselves into a single model.\\

The OSR Kit library\cite{OSRKit} is a flexible implementation of on-stack replacement instrumentation in LLVM.
The source-code for the library is available on Github\cite{OSRKitGit}, and the library can be used in any LLVM project by simply copy-pasting the OSR Kit files inside of it.
The simple integration, the availability of the source code, and the flexibility of the framework make it a perfect base implementation upon which we can implement our support for OSR deoptimization mechanisms in RJIT.\\

OSR Kit library enables to work at the LLVM IR level.
LLVM IR is a stable representation that combines the advantages of both the high-level representation, i.e., it still contains some semantic constructions particular to the language being compiled, and the advantages of a lower level representation, closer to the execution engine.
In the case of this master thesis project, i.e., providing OSR mechanisms in the RJIT project, the LLVM IR is the exact middle layer representation that we need. 
At the LLVM IR level, the R semantics are still visible and it therefore allows us to efficiently implement our optimizations.\\

%TODO MORE ABOUT THE FOCUS ON DEOPT. 
MOVE UP\\

This master project thesis focuses on the design and implementation of a prototype for OSR deoptimization support in RJIT.
Starting a new OSR transition implementation from scratch requires time.
Using a flexible and modifiable OSR transition library therefore seemed like the goto option.
We do not waste time reimplementing something that already exists, and can therefore put all our efforts into implementing an interesting OSR deoptimization case, testing it, and extending the OSR Kit library with mechanisms that are specific to our needs (Sections \ref{osrForUs} and \ref{extendingOSR}).\\

\subsection{Limitations}
%While very flexible, comes short on several points
    %Open OSR, not really fitting our case.
    %Continuation style is fine for optimization, but pretty bad for deopt.
        %no replacement when exits... 
        %many clones ... 
        %As we'll see later, cloning is not sufficient ...
While very flexible, the OSR Kit\cite{OSRKit} library presents several disadvantages and exhibits costly behaviors that do not perfectly fit the deoptimization process.
The main advantage of the open OSR is to leverage profiled-guided compilation strategies to generate efficient code.
However, generating a transformation that removes optimizations is hard and does not play well with the OSR Kit instrumentation.
Such a transformation needs to take into account other optimizations that might have been performed on the code after the optimization was applied, i.e., deoptimizing requires to keep track of which transformations performed on the code depend on this optimization, and undo them.
Moreover, the deoptimization case is used to preserve correctness in the program and must be conservative. 
Performance is a soft issue, and hence leveraging profiled-guided compilation strategies is not our main objective. 
For the OSR point, the framework relies on a StateMap that matches values in the from and the continuation functions.
That implies that, in order to generate the continuation function on the fly for the deoptimization case, one is required to 1) be able to reverse an optimization, that might have interfered with other optimizations, and 2) to generate a correct StateMap to give as input to the OSR Kit machinery.\\

Once an OSR exit is taken, it is more likely to be fired in subsequent calls.
For example, in the case of call site inlining, the OSR exit is fired when the inlined function is redefined.
In subsequent calls, the OSR exit will also be triggered.
As a result, if the OSR exit is an open OSR point, the framework will have to perform expensive operations to generate the correct continuation function every time the OSR exit is triggered.
In the light of these observations, we can conclude that the open OSR design does not fit well the deoptimization case.\\

The resolved OSR corresponds to our requirements for deoptimization.
The optimized version is generated from a base function.
Since OSR points are barriers for subsequent optimizations, i.e., they cannot be tempered with, the mapping between the OSR exit and the base function is guaranteed to be preserved, regardless of the subsequent optimizations performed on the optimized function.
It therefore makes sense to instrument the base function to generate a continuation function for the OSR exit.\\

The OSR Kit way of generating the continuation function is expensive.
In the deoptimization case, inserting an OSR exit requires to 1) clone the base function in order to obtain two copies: one is kept as is, the other will be optimized, 2) generate the continuation function. 
Since the continuation function might have a different signature than the base function, the framework has to generate a clone of the body of the base function that will be instrumented with the OSR ENTRY block.
Moreover, in RJIT, cloning a function is not sufficient.
The LLVM IR attributes\cite{llvmAttribute} associated to the RJIT LLVM IR are used to generate safepoints for call stubs and the garbage collector.
For example, when a call stub is inserted inside a function, a patchpoint identified by a unique id is inserted as an LLVM attribute in the corresponding call instruction, and registered inside the framework as a patchpoint that needs special instrumentation in the final compilation steps.
If not properly set, the call stub will not be resolved at run time and yields unexpected behaviors, e.g., a function call that, instead of being evaluated will return its abstract syntax tree(AST).
Therefore, for every clone, we need to go through the IR and fix the attributes, which makes the OSR instrumentation even more expensive.\\

Finally, as it was the case for the open OSR, the resolved OSR does not take into account the fact that an OSR exit might be triggered at every call, once it has been fired a first time.
Although less expensive than the open OSR, a resolved OSR exit that fires at every execution adds the cost of a function call and return, compared to the base function.
The OSR Kit framework does not provide the mechanisms required to avoid this extra cost.\\

\section{OSR RJIT mechanisms}
This section describes the prototype OSR deoptimization implementation in RJIT. 
The goal of this master thesis is to provide a proof of concept, i.e., experiment with OSR techniques, explore the range of possibilities and the different requirements that are inhering to the RJIT compiler.
The OSR implementation, in RJIT, is based on the OSR Kit\cite{OSRKit} library that we extend with extra mechanisms to fit the deoptimization case.  
\subsection{OSR Handler}
%simplified points
%Keeps track of versions, statemaps etc
%Unables to have a less naive usage of the OSR Kit library
%Talk about the base, toInstrument and Exit versions
%Talk about the patchpoints that are fixed automatically
The OSR Handler is a singleton object used to improve the OSR Kit performance in the case of deoptimization. 
As explained before, deoptimization with OSR Kit suffers from several miss matches between the transition system design, and our own requirements: 
\begin{enumerate}
    \item The OSR Kit requires to generate several clones of the same functions.
    \item The cost of resetting the attributes has to be added to the cost of cloning functions.
    \item The OSR Kit does not take into account the fact that an OSR exit that is fired, will probably be fired for every subsequent calls.
\end{enumerate}
The OSR handler provides mechanisms that tend to mitigate these limitations.\\

In RJIT, the LLVM IR that corresponds to a function goes through several steps.
First, the R AST of the function is translated into LLVM IR, with special machinery to call intrinsics and insert inline cached call stubs, i.e., calls to functions that have to be resolved at run time.
Then, once this IR is generated, the RJIT compiler instruments every registered safepoints and patchpoints in order to add the instrumentation for the garbage collector and the dynamic compilation of ic stubs.
The generated IR is a blotted piece of code from which R semantics are hard to extract.
As a result, most optimizations need to be performed before this final instrumentation.\\

%ADD since in a  jit, function are compiled when they are called. But, the optimization process and the deopt might require to access IR that is in another function. Hence, if was compiled, cannot reuse it and need a fresh one -> cost increases.
The RJIT compiler is a just-in-time compiler, i.e., functions are compiled when they are called.
A function call can be described with the following steps: 1) the function is extracted from the closure, 2) if the type of the function is not native, i.e., if the function was not compiled, the RJIT compiler is invoked, 3) the function call is evaluated.
This ensures that every function that is executed will be compiled in order to obtain the best possible performances, while avoiding the compilation of unused functions.
For OSR transformation mechanisms, however, some functions might need to be compiled ahead of time (AOT).
For example, consider the case of call site inlining.
The optimization is performed at the LLVM IR.
Once the target function of call is identified, the transformation process needs to obtain the LLVM IR of the function to inline.
Moreover, this IR should not be instrumented , i.e., the LLVM IR should not contain the patchpoints and safepoints, in order to allow further optimizations.
Therefore, in any case, the function needs to be recompiled from scratch in order to obtain a fresh non instrumented IR. 
This is an extra cost added to the OSR Kit, particular to the RJIT framework, that we want to remove.
As a result, the OSR Handler provides a mechanism to assign a compiled function to a closure. 
If the transformation process compiles a function that was never jited before, this mechanism will set the compiled version in the closure.
The next call to the function will directly use the compiled version, instead of calling the JIT compiler.
The next paragraph describes our solution to mitigate the compilation cost when the function was already compiled.\\


\subsubsection{Handling version and the fixing the instrumentation}
CLEAN UP AND MAYBE MERGE WITH WALKTHROUGH.\\

The OSR Handler enables to keep track of LLVM IRs that are generated during the optimization process.
The singleton possesses a static map, called a \textit{version map}, that enables to match a symbolic expression closure (i.e., a SEXP of type CLOSXP) to a pair of LLVM functions\cite{llvmFunction}.
A closure contains the function's formals, the function itself, and the environment associated with the function.
The first element of the pair is the LLVM uninstrument base function that corresponds to the closure, without the safepoints and patchpoints instrumentation.
This version can be generated by calling the OSR Handler clone function with the "instrument" flag set at false (see FIGURE), and cannot be used inside a closure.
The OSR clone function automatically registers a StateMap for the original and the cloned function.
The second element is the instrumented LLVM IR of the function and can be used to serve function calls.
If we consider our last example, the version map enables to avoid compiling the same function several times to get a fresh IR. 
When a function needs to be inlined, the user can check if the version map already contains an uninstrumented IR for this function. 
If that is the case, a clone of this function can be used. 
If the version map does not contain an entry for this function, the user can call the OSR Handler compile function to generate a fresh IR, and automatically generate an entry in the version map.\\

\includecode{Code/Clone.cpp}

The LLVM attribute set instrumentation prevents us from easily cloning LLVM functions.
For example, ic stub calls take as argument a pointer to the caller and a unique id that identifies the call.
Both of these need to be fixed in the clone, i.e., the pointer argument must point to the clone and a new id must be generated and registered for the ic stub.
The OSR Handler therefore provides a function to fix the attributes in the LLVM IR and correctly generate safepoints and patchpoints.
This function runs on a function and generates fresh attributes. 
It can be used to either fix the LLVM IR of a function that underwent transformations, e.g., calls were inlined and the instrumentation is broken, or to instrument an LLVM IR obtained from the version map.\\

CODE SIGNATURE.

\subsubsection{Simplifying the OSR points}
%Simplified interface for the OSR points + new mechanism see next section
%Justification: in rjit, especially for the case presented in the case study, need to map exact same instructions. It retrieves the StateMap and 
The OSR Handler provides a simplified API to insert OSR exits.
In the deoptimization case, and more specifically in RJIT, the continuation instruction needs to be the exact match of the from function's last instruction that is not part of the OSR instrumentation.
Furthermore, the continuation function is known in advance to be the base function on which the transformations were performed.
We therefore simplified the API for OSR exits, i.e., the function only takes as inputs the modified function, the source instruction at which we insert the OSR point, the OSR condition, and an optional LLVM call instruction.
The last argument's usage is described in REF.
The OSR Handler generates the correct continuation function from the transformed one, generates the StateMap used by the OSR Kit framework, identifies the correct continuation instruction, and calls the \textit{insertResolvedOSR} function described in REF.\\

API.\\

\subsubsection{Walkthrough a transformation with OSR exits}
%The base function etc. 
Assume a transformation process \textit{TransP}, that needs to insert OSR exits in the generate code.
The transformation takes as input a closure.
It begins by extracting the function from the closure. 
If the function is not compiled(case 1), \textit{TransP} calls the OSR Handler compile function.
The function will compile the code, create a working un-instrumented base copy, register a new entry in the version map, and return the compiled version to \textit{TransP}.
If the function is compiled, the OSRHandler will check if there is a corresponding entry in the version map. 
If not, it performs the same steps as in case 1.
Otherwise, it returns a clone of the un-instrumented IR in the version map.
\textit{TransP} performs its transformations on the IR.
It then proceeds to insert the OSR exit by calling the OSR Handler function \textit{insertOSRExit}.
The continuation function is a clone of the same base function that will be instrumented with the OSR ENTRY block.
The OSR Handler is responsible for generating the correct StateMap between the continuation function and the transformed one.
The OSR Handler then automatically fixes the LLVM attributes on both the transformed and the continuation functions.\\

\subsection{Improving the Exit}
%Put the proper exit ! improve the perf
    %Not rely on compensation code because does not relate to local values per see. Hence we modify the framework to do it for us. We know it is the first block, we just insert before the branch instruction.
%deoptimization improving the performances.
    %replace with the function that is not doing the optimization
    %e.g., inlining
    %OSRHandler two attributes.
As mentioned earlier, 

\section{Future work}
\subsection{On the fly compilation}
%An optimization process?
\subsubsection{Transitive StateMaps}
%Trying to improve the field of possibilities
    %Chain of statemaps, can find what is in common in both of them
    %Why interesting? Will be able, if provides interface, to enlarge the scope of intermixing optimizations 

